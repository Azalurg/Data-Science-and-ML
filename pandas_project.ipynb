{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0686c98e-72e8-46e1-9915-a2eaecb54294",
   "metadata": {},
   "source": [
    "# Pandas tutorial\n",
    "\n",
    "Dataset characteristic:\n",
    "\n",
    "- every folder contain: addresses.csv, addresses_people.csv, people.csv, people_publications.csv, publications.csv.\n",
    "- every file contain few columns, named in first row\n",
    "- every file not with many-to-many relations, contain temp_id column\n",
    "\n",
    "Project:\n",
    "\n",
    "- merge all files into single DataFrame\n",
    "- change current temp_ids into new unique ids\n",
    "- eliminate duplicates (eg. consider address with x percentage of similarity as one)\n",
    "- add column “town” for people.csv data, extracted from “addresses” column in addresses.csv\n",
    "- get missing lat/lng data for every town/address (eg. through google api)\n",
    "- save DataFrame to single csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60c28df-d94c-4ef3-850c-af6274be3620",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84c2760b-9a09-4e55-ab24-7ea552f93a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_percentage = 20\n",
    "\n",
    "data_directory=\"./data\"\n",
    "data_sub_folders = 134\n",
    "data_load_step = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e1edb",
   "metadata": {},
   "source": [
    "## Functions & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "837f5a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from typing import List\n",
    "\n",
    "def move_head(arr, index: int):\n",
    "    arr = arr = [arr[index]] + arr[:index] + arr[index + 1:]\n",
    "\n",
    "def data_filter(name: str, address: str):\n",
    "    data = name.split(\",\") + address.split(\",\")\n",
    "    filtered_data = []\n",
    "    for word in data:\n",
    "        cleaned_word = word.strip().lower()\n",
    "        cleaned_word = re.sub(r'[^a-zA-Z\\s]', ' ', cleaned_word)\n",
    "        cleaned_word = re.sub(r'\\s+', ' ', cleaned_word)\n",
    "        if len(cleaned_word) > 2:\n",
    "            filtered_data.append(cleaned_word.strip())\n",
    "    return \",\".join(filtered_data)\n",
    "            \n",
    "def similarity(data1: str, data2: str):\n",
    "    arr1, arr2 = data1.split(\",\"), data2.split(\",\")\n",
    "    counter = 0\n",
    "    total = max(len(arr1), len(arr2))\n",
    "    for str1 in arr1:\n",
    "        for str2 in arr2:\n",
    "            if str1 in str2 or str2 in str1:\n",
    "                counter += 1\n",
    "    return counter / total * 100\n",
    "\n",
    "def make_id_unique(df, value, column=\"temp_id\"):\n",
    "    df[column] = df[column].apply(lambda id: str(value) + \"_\" + str(id))\n",
    "    return df\n",
    "\n",
    "class GoodAddress:\n",
    "    string: str\n",
    "    uuid: str\n",
    "    children_list: list\n",
    "    def __init__(self, string, uuid) -> None:\n",
    "        self.string = string\n",
    "        self.uuid = uuid\n",
    "        self.children_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d71be7a",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ede55e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_id</th>\n",
       "      <th>address</th>\n",
       "      <th>countries_scope</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>name</th>\n",
       "      <th>phone</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_2</td>\n",
       "      <td>sogn og fjordane university collegesogndal, no...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>faculty of teacher education and sport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_3</td>\n",
       "      <td>university of bergenbergen, norway</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>centre for cancer biomarkers, ccbio, departmen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_4</td>\n",
       "      <td>haukeland university hospitalbergen, norway</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>department of pathology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_4</td>\n",
       "      <td>haukeland university hospitalbergen, norway</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>department of pathology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_5</td>\n",
       "      <td>university of bergenbergen, norway</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>centre for cancer biomarkers, ccbio, departmen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203334</th>\n",
       "      <td>133_1464</td>\n",
       "      <td>division of environmental medicinenorwegian in...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>department of air pollution and noise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203335</th>\n",
       "      <td>133_1465</td>\n",
       "      <td>division of environmental medicinenorwegian in...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>department of air pollution and noise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203336</th>\n",
       "      <td>133_1466</td>\n",
       "      <td>division of environmental medicinenorwegian in...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>department of air pollution and noise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203337</th>\n",
       "      <td>133_1467</td>\n",
       "      <td>division of environmental medicinenorwegian in...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>department of air pollution and noise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203338</th>\n",
       "      <td>133_1468</td>\n",
       "      <td>university hospital of north norwaytromsø, norway</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>department of gastrointestinal surgery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203339 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         temp_id                                            address  \\\n",
       "0            0_2  sogn og fjordane university collegesogndal, no...   \n",
       "1            0_3                 university of bergenbergen, norway   \n",
       "2            0_4        haukeland university hospitalbergen, norway   \n",
       "3            0_4        haukeland university hospitalbergen, norway   \n",
       "4            0_5                 university of bergenbergen, norway   \n",
       "...          ...                                                ...   \n",
       "203334  133_1464  division of environmental medicinenorwegian in...   \n",
       "203335  133_1465  division of environmental medicinenorwegian in...   \n",
       "203336  133_1466  division of environmental medicinenorwegian in...   \n",
       "203337  133_1467  division of environmental medicinenorwegian in...   \n",
       "203338  133_1468  university hospital of north norwaytromsø, norway   \n",
       "\n",
       "       countries_scope  lat  lon  \\\n",
       "0                   NO  NaN  NaN   \n",
       "1                   NO  NaN  NaN   \n",
       "2                   NO  NaN  NaN   \n",
       "3                   NO  NaN  NaN   \n",
       "4                   NO  NaN  NaN   \n",
       "...                ...  ...  ...   \n",
       "203334              NO  NaN  NaN   \n",
       "203335              NO  NaN  NaN   \n",
       "203336              NO  NaN  NaN   \n",
       "203337              NO  NaN  NaN   \n",
       "203338              NO  NaN  NaN   \n",
       "\n",
       "                                                     name  phone  url  \n",
       "0                  faculty of teacher education and sport    NaN  NaN  \n",
       "1       centre for cancer biomarkers, ccbio, departmen...    NaN  NaN  \n",
       "2                                 department of pathology    NaN  NaN  \n",
       "3                                 department of pathology    NaN  NaN  \n",
       "4       centre for cancer biomarkers, ccbio, departmen...    NaN  NaN  \n",
       "...                                                   ...    ...  ...  \n",
       "203334              department of air pollution and noise    NaN  NaN  \n",
       "203335              department of air pollution and noise    NaN  NaN  \n",
       "203336              department of air pollution and noise    NaN  NaN  \n",
       "203337              department of air pollution and noise    NaN  NaN  \n",
       "203338             department of gastrointestinal surgery    NaN  NaN  \n",
       "\n",
       "[203339 rows x 8 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = {\"addresses\": [], \"addresses_people\": [], \"people\": [], \"people_publications\": [], \"publications\": []}\n",
    "\n",
    "for i in range(0, data_sub_folders, data_load_step):\n",
    "    data_files[\"addresses\"].append(make_id_unique(pd.read_csv(os.path.join(data_directory, f\"{i}/ADDRESSES.csv\")), i))\n",
    "    data_files[\"addresses_people\"].append(make_id_unique(make_id_unique(pd.read_csv(os.path.join(data_directory, f\"{i}/ADDRESSES_PEOPLE.csv\")), i, \"address_uuid\"), i, \"person_uuid\"))\n",
    "    data_files[\"people\"].append(make_id_unique(pd.read_csv(os.path.join(data_directory, f\"{i}/PEOPLE.csv\")), i))\n",
    "    data_files[\"people_publications\"].append(make_id_unique(make_id_unique(pd.read_csv(os.path.join(data_directory, f\"{i}/PEOPLE_PUBLICATIONS.csv\")), i, \"person_uuid\"), i, \"publication_uuid\"))\n",
    "    data_files[\"publications\"].append(make_id_unique(pd.read_csv(os.path.join(data_directory, f\"{i}/PUBLICATIONS.csv\")), i))\n",
    "\n",
    "address_df = pd.concat(data_files[\"addresses\"], ignore_index=True)\n",
    "addresses_people_df = pd.concat(data_files[\"addresses_people\"], ignore_index=True)\n",
    "people_df = pd.concat(data_files[\"people\"], ignore_index=True)\n",
    "people_publications_df = pd.concat(data_files[\"people_publications\"], ignore_index=True)\n",
    "publications_df = pd.concat(data_files[\"publications\"], ignore_index=True)\n",
    "\n",
    "address_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9e0a34",
   "metadata": {},
   "source": [
    "## Prepare good addresses indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bef5beeb-67f0-46ce-9c4a-521218cc826d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217 good addresses found\n",
      "CPU times: user 15.4 s, sys: 7.39 ms, total: 15.4 s\n",
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "address_df[\"full_address\"] = address_df.apply(lambda x: data_filter(str(x[\"name\"]), str(x[\"address\"])), axis=1)\n",
    "\n",
    "good_address_list: List[GoodAddress] = []\n",
    "\n",
    "for address_index, address in address_df.iterrows():\n",
    "    flag = True\n",
    "    for good_address_index, ga in enumerate(good_address_list):\n",
    "        if similarity(ga.string, address[\"full_address\"]) > similarity_percentage:\n",
    "            flag = False\n",
    "            ga.children_list.append(address[\"temp_id\"])\n",
    "            move_head(good_address_list, good_address_index)\n",
    "            break\n",
    "    if flag:    \n",
    "        good_address_list.append(GoodAddress(address[\"full_address\"], address[\"temp_id\"]))\n",
    "\n",
    "address_df = address_df.drop([\"full_address\"], axis=1)\n",
    "\n",
    "print(f\"{len(good_address_list)} good addresses found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bbae6a",
   "metadata": {},
   "source": [
    "## Update ADDRESSES_PEOPLE relation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a266419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "20\n",
      "30\n",
      "44\n",
      "59\n",
      "65\n",
      "82\n",
      "118\n",
      "224\n",
      "352\n",
      "360\n",
      "457\n",
      "462\n",
      "492\n",
      "552\n",
      "554\n",
      "715\n",
      "735\n",
      "905\n",
      "937\n",
      "959\n",
      "1033\n",
      "1224\n",
      "1227\n",
      "1467\n",
      "1646\n",
      "1875\n",
      "1979\n",
      "2068\n",
      "2197\n",
      "2198\n",
      "2250\n",
      "2305\n",
      "2319\n",
      "2944\n",
      "3165\n",
      "3289\n",
      "3532\n",
      "3659\n",
      "4402\n",
      "4480\n",
      "6220\n",
      "6511\n",
      "7163\n",
      "7280\n",
      "7608\n",
      "7953\n",
      "8251\n",
      "8314\n",
      "8460\n",
      "8773\n",
      "9364\n",
      "9590\n",
      "10151\n",
      "10394\n",
      "10695\n",
      "11112\n",
      "11986\n",
      "12122\n",
      "12426\n",
      "12656\n",
      "14007\n",
      "14475\n",
      "15182\n",
      "15286\n",
      "15500\n",
      "16193\n",
      "16655\n",
      "17594\n",
      "17856\n",
      "18094\n",
      "18271\n",
      "18470\n",
      "19612\n",
      "20534\n",
      "20680\n",
      "20726\n",
      "21031\n",
      "21071\n",
      "21681\n",
      "21709\n",
      "22341\n",
      "24264\n",
      "26195\n",
      "26644\n",
      "26916\n",
      "28088\n",
      "28118\n",
      "28263\n",
      "28754\n",
      "29347\n",
      "29838\n",
      "29846\n",
      "30297\n",
      "32032\n",
      "33644\n",
      "33940\n",
      "34625\n",
      "34951\n",
      "35697\n",
      "36223\n",
      "39539\n",
      "40279\n",
      "40692\n",
      "41002\n",
      "42307\n",
      "43257\n",
      "43361\n",
      "43744\n",
      "43783\n",
      "44377\n",
      "44614\n",
      "46155\n",
      "46437\n",
      "47242\n",
      "47347\n",
      "47931\n",
      "48809\n",
      "49394\n",
      "49909\n",
      "50234\n",
      "51664\n",
      "52055\n",
      "52145\n",
      "52391\n",
      "55435\n",
      "56134\n",
      "57189\n",
      "57628\n",
      "58375\n",
      "59828\n",
      "61249\n",
      "65275\n",
      "66080\n",
      "66915\n",
      "68228\n",
      "68767\n",
      "69240\n",
      "70933\n",
      "73047\n",
      "76726\n",
      "76997\n",
      "77175\n",
      "78458\n",
      "78595\n",
      "80038\n",
      "81685\n",
      "82785\n",
      "83886\n",
      "85936\n",
      "86779\n",
      "87078\n",
      "88047\n",
      "91325\n",
      "91675\n",
      "91716\n",
      "92126\n",
      "92529\n",
      "94207\n",
      "98150\n",
      "99486\n",
      "101243\n",
      "101363\n",
      "102254\n",
      "103766\n",
      "105767\n",
      "108252\n",
      "109258\n",
      "109412\n",
      "110966\n",
      "111738\n",
      "117178\n",
      "117537\n",
      "117936\n",
      "119060\n",
      "119680\n",
      "119877\n",
      "121196\n",
      "121567\n",
      "121682\n",
      "123138\n",
      "126237\n",
      "129887\n",
      "130147\n",
      "133285\n",
      "134014\n",
      "134431\n",
      "135391\n",
      "139579\n",
      "139696\n",
      "141425\n",
      "142460\n",
      "143990\n",
      "144928\n",
      "145870\n",
      "147268\n",
      "147425\n",
      "155542\n",
      "156263\n",
      "159929\n",
      "160139\n",
      "165115\n",
      "167712\n",
      "168891\n",
      "169569\n",
      "169806\n",
      "172436\n",
      "174424\n",
      "176195\n",
      "184585\n",
      "186454\n",
      "188554\n",
      "189964\n",
      "190333\n",
      "193257\n",
      "195105\n"
     ]
    }
   ],
   "source": [
    "for address_str, good_address_index, to_update_address_list in good_address_list:\n",
    "    for to_replace_address_index in to_update_address_list:\n",
    "        addresses_people_df.loc[to_replace_address_index, \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d6c8e3",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94732f1b-6a7b-4223-a17a-5d0ff304b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for it in os.scandir(\"./data\"):\n",
    "    print(it)\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(\"./data/\"):\n",
    "    if dirnames:\n",
    "        continue\n",
    "    addresses = pd.read_table(os.path.join(dirpath, \"ADDRESSES.csv\"), sep=',')\n",
    "    addresses_people = pd.read_table(os.path.join(dirpath, \"ADDRESSES_PEOPLE.csv\"), sep=',')\n",
    "    people = pd.read_table(os.path.join(dirpath, \"PEOPLE.csv\"), sep=\",\")\n",
    "    people_publications = pd.read_table(os.path.join(dirpath, \"PEOPLE_PUBLICATIONS.csv\"), sep=\",\")\n",
    "    publications = pd.read_table(os.path.join(dirpath, \"PUBLICATIONS.csv\"), sep=\",\")\n",
    "\n",
    "    addresses.rename(columns={\"temp_id\": \"address_uuid\"}, inplace=True)\n",
    "    people.rename(columns={\"temp_id\": \"person_uuid\"}, inplace=True)\n",
    "    publications.rename(columns={\"temp_id\": \"publication_uuid\"}, inplace=True)\n",
    "    \n",
    "    merged_1 = pd.merge(addresses, addresses_people, on='address_uuid', how=\"inner\")\n",
    "    merged_2 = pd.merge(merged_1, people, on=\"person_uuid\", how=\"inner\")\n",
    "    merged_3 = pd.merge(merged_2, people_publications, on=\"person_uuid\", how=\"inner\")\n",
    "    data = pd.merge(merged_3, publications, on=\"publication_uuid\", how=\"inner\")\n",
    "\n",
    "    dfs.append(data)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43c1184-133c-4495-9cba-99a6b654fc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = df['address_uuid'].astype(str) + \"_\" + df['person_uuid'].astype(str) + \"_\" + df['publication_uuid'].astype(str)\n",
    "df = df[['id'] + [col for col in df.columns if col != 'id']]\n",
    "df.drop(columns=['address_uuid', 'person_uuid', \"publication_uuid\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f8b3cc-1534-475b-b325-b3fa33b0571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('address').size().reset_index(name='count').sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4243df-8e11-4fd2-8e8b-666e7fe88149",
   "metadata": {},
   "outputs": [],
   "source": [
    "visited = set()\n",
    "c = 0\n",
    "i = 0\n",
    "for index, row in df.iterrows():\n",
    "    i+=1\n",
    "    current_address = row['address']\n",
    "    current_name = row['name']\n",
    "    v = str(current_address) + \", \" + str(current_name)\n",
    "    if v in visited:\n",
    "        c += 1\n",
    "        continue\n",
    "    visited.add(v)\n",
    "\n",
    "c, i, c-i\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6735721-09a5-450e-adb3-6ce4f6e6b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[1, \"firstname\"] = \"Paweł\"\n",
    "df.iloc[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
