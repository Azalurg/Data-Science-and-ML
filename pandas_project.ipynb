{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0686c98e-72e8-46e1-9915-a2eaecb54294",
   "metadata": {},
   "source": [
    "# Pandas tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60c28df-d94c-4ef3-850c-af6274be3620",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c2760b-9a09-4e55-ab24-7ea552f93a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_percentage = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e1edb",
   "metadata": {},
   "source": [
    "## Functions & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "837f5a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def move_head(arr, index: int):\n",
    "    arr = arr = [arr[index]] + arr[:index] + arr[index + 1:]\n",
    "\n",
    "def data_filter(name: str, address: str):\n",
    "    data = name.split(\",\") + address.split(\",\")\n",
    "    filtered_data = []\n",
    "    for word in data:\n",
    "        cleaned_word = word.strip().lower()\n",
    "        cleaned_word = re.sub(r'[^a-zA-Z\\s]', ' ', cleaned_word)\n",
    "        cleaned_word = re.sub(r'\\s+', ' ', cleaned_word)\n",
    "        if len(cleaned_word) > 2:\n",
    "            filtered_data.append(cleaned_word.strip())\n",
    "    return \",\".join(filtered_data)\n",
    "            \n",
    "def similarity(data1: str, data2: str):\n",
    "    arr1, arr2 = data1.split(\",\"), data2.split(\",\")\n",
    "    counter = 0\n",
    "    total = max(len(arr1), len(arr2))\n",
    "    for str1 in arr1:\n",
    "        for str2 in arr2:\n",
    "            if str1 in str2 or str2 in str1:\n",
    "                counter += 1\n",
    "    return counter / total * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9e0a34",
   "metadata": {},
   "source": [
    "## Prepare addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bef5beeb-67f0-46ce-9c4a-521218cc826d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 good addresses found\n",
      "CPU times: user 14.1 s, sys: 48.2 ms, total: 14.2 s\n",
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "address_list = []\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(\"./data/\"):\n",
    "    if dirnames:\n",
    "        continue\n",
    "    data = pd.read_table(os.path.join(dirpath, \"ADDRESSES.csv\"), sep=',')\n",
    "    address_list.append(data)\n",
    "\n",
    "address_df: pd.DataFrame = pd.concat(address_list, ignore_index=True)\n",
    "address_df[\"full_address\"] = address_df.apply(lambda x: data_filter(str(x[\"name\"]), str(x[\"address\"])), axis=1)\n",
    "\n",
    "good_address_list = []\n",
    "\n",
    "for address_index, address in address_df.iterrows():\n",
    "    flag = True\n",
    "    for good_address_index, ga in enumerate(good_address_list):\n",
    "        if similarity(ga[0], address[\"full_address\"]) > similarity_percentage:\n",
    "            flag = False\n",
    "            ga[2].append(address_index)\n",
    "            move_head(good_address_list, good_address_index)\n",
    "            break\n",
    "    if flag:    \n",
    "        good_address_list.append((address[\"full_address\"], address_index, []))\n",
    "\n",
    "print(f\"{len(good_address_list)} good addresses found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bbae6a",
   "metadata": {},
   "source": [
    "## Update ADDRESSES_PEOPLE relation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94732f1b-6a7b-4223-a17a-5d0ff304b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(\"./data/\"):\n",
    "    if dirnames:\n",
    "        continue\n",
    "    addresses = pd.read_table(os.path.join(dirpath, \"ADDRESSES.csv\"), sep=',')\n",
    "    addresses_people = pd.read_table(os.path.join(dirpath, \"ADDRESSES_PEOPLE.csv\"), sep=',')\n",
    "    people = pd.read_table(os.path.join(dirpath, \"PEOPLE.csv\"), sep=\",\")\n",
    "    people_publications = pd.read_table(os.path.join(dirpath, \"PEOPLE_PUBLICATIONS.csv\"), sep=\",\")\n",
    "    publications = pd.read_table(os.path.join(dirpath, \"PUBLICATIONS.csv\"), sep=\",\")\n",
    "\n",
    "    addresses.rename(columns={\"temp_id\": \"address_uuid\"}, inplace=True)\n",
    "    people.rename(columns={\"temp_id\": \"person_uuid\"}, inplace=True)\n",
    "    publications.rename(columns={\"temp_id\": \"publication_uuid\"}, inplace=True)\n",
    "    \n",
    "    merged_1 = pd.merge(addresses, addresses_people, on='address_uuid', how=\"inner\")\n",
    "    merged_2 = pd.merge(merged_1, people, on=\"person_uuid\", how=\"inner\")\n",
    "    merged_3 = pd.merge(merged_2, people_publications, on=\"person_uuid\", how=\"inner\")\n",
    "    data = pd.merge(merged_3, publications, on=\"publication_uuid\", how=\"inner\")\n",
    "\n",
    "    dfs.append(data)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43c1184-133c-4495-9cba-99a6b654fc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = df['address_uuid'].astype(str) + \"_\" + df['person_uuid'].astype(str) + \"_\" + df['publication_uuid'].astype(str)\n",
    "df = df[['id'] + [col for col in df.columns if col != 'id']]\n",
    "df.drop(columns=['address_uuid', 'person_uuid', \"publication_uuid\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f8b3cc-1534-475b-b325-b3fa33b0571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('address').size().reset_index(name='count').sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4243df-8e11-4fd2-8e8b-666e7fe88149",
   "metadata": {},
   "outputs": [],
   "source": [
    "visited = set()\n",
    "c = 0\n",
    "i = 0\n",
    "for index, row in df.iterrows():\n",
    "    i+=1\n",
    "    current_address = row['address']\n",
    "    current_name = row['name']\n",
    "    v = str(current_address) + \", \" + str(current_name)\n",
    "    if v in visited:\n",
    "        c += 1\n",
    "        continue\n",
    "    visited.add(v)\n",
    "\n",
    "c, i, c-i\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6735721-09a5-450e-adb3-6ce4f6e6b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[1, \"firstname\"] = \"Pawe≈Ç\"\n",
    "df.iloc[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
