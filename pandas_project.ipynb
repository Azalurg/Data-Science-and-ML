{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0686c98e-72e8-46e1-9915-a2eaecb54294",
   "metadata": {},
   "source": [
    "# Pandas tutorial\n",
    "\n",
    "Dataset characteristic:\n",
    "\n",
    "- every folder contain: addresses.csv, addresses_people.csv, people.csv, people_publications.csv, publications.csv.\n",
    "- every file contain few columns, named in first row\n",
    "- every file not with many-to-many relations, contain temp_id column\n",
    "\n",
    "Project:\n",
    "\n",
    "- merge all files into single DataFrame\n",
    "- change current temp_ids into new unique ids\n",
    "- eliminate duplicates (eg. consider address with x percentage of similarity as one)\n",
    "- add column “town” for people.csv data, extracted from “addresses” column in addresses.csv\n",
    "- get missing lat/lng data for every town/address (eg. through google api)\n",
    "- save DataFrame to single csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60c28df-d94c-4ef3-850c-af6274be3620",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84c2760b-9a09-4e55-ab24-7ea552f93a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_percentage = 20\n",
    "\n",
    "data_directory=\"./data\"\n",
    "data_sub_folders = 134\n",
    "data_load_step = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e1edb",
   "metadata": {},
   "source": [
    "## Functions & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "837f5a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from typing import List\n",
    "\n",
    "def move_head(arr, index: int):\n",
    "    arr = arr = [arr[index]] + arr[:index] + arr[index + 1:]\n",
    "\n",
    "def data_filter(name: str, address: str):\n",
    "    data = name.split(\",\") + address.split(\",\")\n",
    "    filtered_data = []\n",
    "    for word in data:\n",
    "        cleaned_word = word.strip().lower()\n",
    "        cleaned_word = re.sub(r'[^a-zA-Z\\s]', ' ', cleaned_word)\n",
    "        cleaned_word = re.sub(r'\\s+', ' ', cleaned_word)\n",
    "        if len(cleaned_word) > 2:\n",
    "            filtered_data.append(cleaned_word.strip())\n",
    "    return \",\".join(filtered_data)\n",
    "            \n",
    "def similarity(data1: str, data2: str):\n",
    "    arr1, arr2 = data1.split(\",\"), data2.split(\",\")\n",
    "    counter = 0\n",
    "    total = max(len(arr1), len(arr2))\n",
    "    for str1 in arr1:\n",
    "        for str2 in arr2:\n",
    "            if str1 in str2 or str2 in str1:\n",
    "                counter += 1\n",
    "    return counter / total * 100\n",
    "\n",
    "def make_id_unique(df, value, column=\"temp_id\"):\n",
    "    df[column] = df[column].apply(lambda id: str(value) + \"_\" + str(id))\n",
    "    return df\n",
    "\n",
    "class GoodAddress:\n",
    "    string: str\n",
    "    uuid: str\n",
    "    children_list: list\n",
    "    def __init__(self, string, uuid) -> None:\n",
    "        self.string = string\n",
    "        self.uuid = uuid\n",
    "        self.children_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d71be7a",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ede55e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_uuid</th>\n",
       "      <th>address</th>\n",
       "      <th>countries_scope</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>name</th>\n",
       "      <th>phone</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_2</td>\n",
       "      <td>sogn og fjordane university collegesogndal, no...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>faculty of teacher education and sport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_3</td>\n",
       "      <td>university of bergenbergen, norway</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>centre for cancer biomarkers, ccbio, departmen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_4</td>\n",
       "      <td>haukeland university hospitalbergen, norway</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>department of pathology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_4</td>\n",
       "      <td>haukeland university hospitalbergen, norway</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>department of pathology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_5</td>\n",
       "      <td>university of bergenbergen, norway</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>centre for cancer biomarkers, ccbio, departmen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203334</th>\n",
       "      <td>133_1464</td>\n",
       "      <td>division of environmental medicinenorwegian in...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>department of air pollution and noise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203335</th>\n",
       "      <td>133_1465</td>\n",
       "      <td>division of environmental medicinenorwegian in...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>department of air pollution and noise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203336</th>\n",
       "      <td>133_1466</td>\n",
       "      <td>division of environmental medicinenorwegian in...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>department of air pollution and noise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203337</th>\n",
       "      <td>133_1467</td>\n",
       "      <td>division of environmental medicinenorwegian in...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>department of air pollution and noise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203338</th>\n",
       "      <td>133_1468</td>\n",
       "      <td>university hospital of north norwaytromsø, norway</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>department of gastrointestinal surgery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203339 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       address_uuid                                            address  \\\n",
       "0               0_2  sogn og fjordane university collegesogndal, no...   \n",
       "1               0_3                 university of bergenbergen, norway   \n",
       "2               0_4        haukeland university hospitalbergen, norway   \n",
       "3               0_4        haukeland university hospitalbergen, norway   \n",
       "4               0_5                 university of bergenbergen, norway   \n",
       "...             ...                                                ...   \n",
       "203334     133_1464  division of environmental medicinenorwegian in...   \n",
       "203335     133_1465  division of environmental medicinenorwegian in...   \n",
       "203336     133_1466  division of environmental medicinenorwegian in...   \n",
       "203337     133_1467  division of environmental medicinenorwegian in...   \n",
       "203338     133_1468  university hospital of north norwaytromsø, norway   \n",
       "\n",
       "       countries_scope  lat  lon  \\\n",
       "0                   NO  NaN  NaN   \n",
       "1                   NO  NaN  NaN   \n",
       "2                   NO  NaN  NaN   \n",
       "3                   NO  NaN  NaN   \n",
       "4                   NO  NaN  NaN   \n",
       "...                ...  ...  ...   \n",
       "203334              NO  NaN  NaN   \n",
       "203335              NO  NaN  NaN   \n",
       "203336              NO  NaN  NaN   \n",
       "203337              NO  NaN  NaN   \n",
       "203338              NO  NaN  NaN   \n",
       "\n",
       "                                                     name  phone  url  \n",
       "0                  faculty of teacher education and sport    NaN  NaN  \n",
       "1       centre for cancer biomarkers, ccbio, departmen...    NaN  NaN  \n",
       "2                                 department of pathology    NaN  NaN  \n",
       "3                                 department of pathology    NaN  NaN  \n",
       "4       centre for cancer biomarkers, ccbio, departmen...    NaN  NaN  \n",
       "...                                                   ...    ...  ...  \n",
       "203334              department of air pollution and noise    NaN  NaN  \n",
       "203335              department of air pollution and noise    NaN  NaN  \n",
       "203336              department of air pollution and noise    NaN  NaN  \n",
       "203337              department of air pollution and noise    NaN  NaN  \n",
       "203338             department of gastrointestinal surgery    NaN  NaN  \n",
       "\n",
       "[203339 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = {\"addresses\": [], \"addresses_people\": [], \"people\": [], \"people_publications\": [], \"publications\": []}\n",
    "\n",
    "for i in range(0, data_sub_folders, data_load_step):\n",
    "    data_files[\"addresses\"].append(make_id_unique(pd.read_csv(os.path.join(data_directory, f\"{i}/ADDRESSES.csv\")), i))\n",
    "    data_files[\"addresses_people\"].append(make_id_unique(make_id_unique(pd.read_csv(os.path.join(data_directory, f\"{i}/ADDRESSES_PEOPLE.csv\")), i, \"address_uuid\"), i, \"person_uuid\"))\n",
    "    data_files[\"people\"].append(make_id_unique(pd.read_csv(os.path.join(data_directory, f\"{i}/PEOPLE.csv\")), i))\n",
    "    data_files[\"people_publications\"].append(make_id_unique(make_id_unique(pd.read_csv(os.path.join(data_directory, f\"{i}/PEOPLE_PUBLICATIONS.csv\")), i, \"person_uuid\"), i, \"publication_uuid\"))\n",
    "    data_files[\"publications\"].append(make_id_unique(pd.read_csv(os.path.join(data_directory, f\"{i}/PUBLICATIONS.csv\")), i))\n",
    "\n",
    "address_df = pd.concat(data_files[\"addresses\"], ignore_index=True)\n",
    "addresses_people_df = pd.concat(data_files[\"addresses_people\"], ignore_index=True)\n",
    "people_df = pd.concat(data_files[\"people\"], ignore_index=True)\n",
    "people_publications_df = pd.concat(data_files[\"people_publications\"], ignore_index=True)\n",
    "publications_df = pd.concat(data_files[\"publications\"], ignore_index=True)\n",
    "\n",
    "address_df.rename(columns={\"temp_id\": \"address_uuid\"}, inplace=True)\n",
    "people_df.rename(columns={\"temp_id\": \"person_uuid\"}, inplace=True)\n",
    "publications_df.rename(columns={\"temp_id\": \"publication_uuid\"}, inplace=True)\n",
    "\n",
    "address_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9e0a34",
   "metadata": {},
   "source": [
    "## Prepare good addresses indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bef5beeb-67f0-46ce-9c4a-521218cc826d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217 good addresses found\n",
      "CPU times: user 14.9 s, sys: 7.96 ms, total: 15 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "address_df[\"full_address\"] = address_df.apply(lambda x: data_filter(str(x[\"name\"]), str(x[\"address\"])), axis=1)\n",
    "\n",
    "good_address_list: List[GoodAddress] = []\n",
    "\n",
    "for address_index, address in address_df.iterrows():\n",
    "    flag = True\n",
    "    for good_address_index, ga in enumerate(good_address_list):\n",
    "        if similarity(ga.string, address[\"full_address\"]) > similarity_percentage:\n",
    "            flag = False\n",
    "            ga.children_list.append(address[\"address_uuid\"])\n",
    "            move_head(good_address_list, good_address_index)\n",
    "            break\n",
    "    if flag:    \n",
    "        good_address_list.append(GoodAddress(address[\"full_address\"], address[\"address_uuid\"]))\n",
    "\n",
    "address_df = address_df.drop([\"full_address\"], axis=1)\n",
    "\n",
    "print(f\"{len(good_address_list)} good addresses found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bbae6a",
   "metadata": {},
   "source": [
    "## Update ADDRESSES_PEOPLE relation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a266419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "replace_map = {to_replace_address_id: good_address.uuid for good_address in good_address_list for to_replace_address_id in good_address.children_list}\n",
    "addresses_people_df[\"address_uuid\"] = addresses_people_df[\"address_uuid\"].map(replace_map).fillna(addresses_people_df[\"address_uuid\"])\n",
    "unique_address_count = addresses_people_df['address_uuid'].nunique()\n",
    "print(unique_address_count <= len(good_address_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d6c8e3",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94732f1b-6a7b-4223-a17a-5d0ff304b481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204431\n"
     ]
    }
   ],
   "source": [
    "merged_1 = pd.merge(people_df, addresses_people_df, on='person_uuid', how=\"inner\")\n",
    "merged_2 = pd.merge(merged_1, address_df, on=\"address_uuid\", how=\"inner\")\n",
    "merged_3 = pd.merge(merged_2, people_publications_df, on=\"person_uuid\", how=\"inner\")\n",
    "one_big_df = pd.merge(merged_3, publications_df, on=\"publication_uuid\", how=\"inner\")\n",
    "\n",
    "print(len(one_big_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e43c1184-133c-4495-9cba-99a6b654fc61",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maddress_uuid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperson_uuid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublication_uuid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maddress_uuid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperson_uuid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpublication_uuid\u001b[39m\u001b[38;5;124m\"\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['id'] = df['address_uuid'].astype(str) + \"_\" + df['person_uuid'].astype(str) + \"_\" + df['publication_uuid'].astype(str)\n",
    "df = df[['id'] + [col for col in df.columns if col != 'id']]\n",
    "df.drop(columns=['address_uuid', 'person_uuid', \"publication_uuid\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f8b3cc-1534-475b-b325-b3fa33b0571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('address').size().reset_index(name='count').sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4243df-8e11-4fd2-8e8b-666e7fe88149",
   "metadata": {},
   "outputs": [],
   "source": [
    "visited = set()\n",
    "c = 0\n",
    "i = 0\n",
    "for index, row in df.iterrows():\n",
    "    i+=1\n",
    "    current_address = row['address']\n",
    "    current_name = row['name']\n",
    "    v = str(current_address) + \", \" + str(current_name)\n",
    "    if v in visited:\n",
    "        c += 1\n",
    "        continue\n",
    "    visited.add(v)\n",
    "\n",
    "c, i, c-i\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6735721-09a5-450e-adb3-6ce4f6e6b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[1, \"firstname\"] = \"Paweł\"\n",
    "df.iloc[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
